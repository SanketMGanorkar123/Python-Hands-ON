{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Objective of Deep Learning \n",
    "* To bulid an AI system capable enough to predict and to take decision on behalf of Human Being.\n",
    "\n",
    "> Disadvantage of Machine Learning\n",
    "* We are able to build a model on;y on structured data in machine learning.\n",
    "\n",
    "> Deep Learning is applicable to Unstructured Data.\n",
    "> Types of Unstructured Data\n",
    "1. Text > Recurrent Neural Network\n",
    "2. Image \n",
    "3. Audio\n",
    "4. Video \n",
    "\n",
    "> Text \n",
    "* Example if we have 200 to 300 Sentences and suppose we have 10,000 words each word will act as Individual Features and because of which our dimensionality of datasets gets increased (In Naive Bayes and SVM we can handle features upto 2000 and beyond that it will not work coorectly)\n",
    "\n",
    "> Image \n",
    "* In case of image (Image is created by multiple pixels)\n",
    "* Resolution > Count of pixels >> Examples >> HD , Ultra HD\n",
    "* Example of my Laptop 14 inch laptop >> Resolutions >> 1920 * 1080 >> 20,73,500 are the total number of pixels.\n",
    "* In Image each pixel acts as an Feature.\n",
    "* In Such Cases Machine Learning model will not work good for such amount of features and because of which we use Deep Learning.\n",
    "\n",
    "> Performance graph between ML and DL \n",
    "* DL can handle more complex data then ML and thats why DL came in use.\n",
    "* ML is suitable for simple data and DL can handle more complex data.\n",
    "* Complex data is that in the data we have curse of dimensionality(High Dimensional Data) and number of records is also high (Number of Rows)\n",
    "\n",
    "> Use of Unstructured Data\n",
    "1. Text data (NLP >> RNN ,LSTM(Big Brother of RNN)) >> In case of chatgpt we give text data input and the output we get from it is also in text format in its own language >> Language Translation\n",
    "2. Image data (CNN,ANN) >> AI image >> Lenskart(Choossing Frames options)\n",
    "3. Audio Data (Audio Analytics) >> Voice Cloning >> Audio data of customers can be used by industry to see if the customer is happy or not while talking to customer Service.\n",
    "4. Video Analytics >> Example >> We know our universe is continously expanding so to calculate the distance of the objects(Planets) NASA uses video analytics to calculate distance between the objects, >> In terms of Crash Test for safety ratings previously multiple crash tests were done to calculate the safety of the car by use of video analytics we can reduce the number of crashes and instead get notible insights from the crash test video taken one time.\n",
    "\n",
    "> CPU (Central Processing Unit)\n",
    "* General purpose processor for a wide range of tasks.\n",
    "* Few powerful cores optimized for sequential processing.\n",
    "* Suited for complex decision making and control flow.\n",
    "\n",
    "> GPU (Graphics Processing Unit)\n",
    "* Originally designed for graphics rendering and parallel processing.\n",
    "* Many small Specialized cores for parallel tasks.\n",
    "* Suited for parallelizable tasks like graphics,machine learning and simulations.\n",
    "\n",
    "> Cardinality \n",
    "* If we have Categorical data in target column we need to do label encoding.\n",
    "* Label encoding is done when we have order in our Categorical data.In Case of label encoding if we have more values, then the model can give higher weightage for maximum values(If we have more than 3 to 4 Categorical data)\n",
    "* In One hot encoding we will get more features anf there will be curse of Dimensionality which is not Good.\n",
    "* Having many categorical values in our features is called as Cardinality.\n",
    "* In such cases we use only one technique by deciding the weight of each category and the error associated with that category in that feature , in this way we select only category which has high presence and low error.\n",
    "* Cardinality affects vertically in the dataset (In terms of rows)\n",
    "\n",
    "> Curse of Dimensionality\n",
    "* Higher number of Indepndent features causes Curse of Dimensionality.\n",
    "* It affects data Vertically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Objective Of Deep learning \n",
    "* To build an AI system capable enough to predict and make decision on behalf of Human being.\n",
    "\n",
    "> Disadvantage of MAchine Learning\n",
    "* We are able to build Efficient model on UNstructured data.\n",
    "\n",
    "> Deep learning is mostly applicable for Unstructured data\n",
    "> TYpes of Unstructured data\n",
    "1. Text > Recurrent Neural Network\n",
    "2. Images\n",
    "3. Audio \n",
    "4. Video\n",
    "\n",
    "> Text \n",
    "* Example we have 200 to 300 sentences and suppose we have 10,000 words in them each word will act as independent feature and because of which our dimensionality of dataset gets increased(In Naive Bayes and SVM we can handle features upto 2000 beyond that it will not work perfectly)\n",
    "\n",
    "> Image \n",
    "* In Case of Image (Image is created by multiple pixels)\n",
    "* Resolution > Count of pixels >> Examples >> HD,Ultra HD\n",
    "* 14 inch Laptop >> Resolution >> 1920 * 1080 >> 20,73,500 Pixels on my Laptop.\n",
    "* In Image Data each pixel act as independent feature.\n",
    "* In such cases Machine Learning model will not work perfectly for such amount of features and because of which we use Deep Learning.\n",
    "\n",
    "> Performance graph between ML and DL \n",
    "* DL can handle more complex data then ML , and so DL came in Use.\n",
    "* ML is suitable for simple data and DL is suitable for complex data.\n",
    "* Complex data is that data which have curse of dimensionality(No of columns is geater than no of rows) and also the number of records is also high(Numbr of rows is also High)\n",
    "\n",
    "> Use of Unstructured data \n",
    "1. Text data (NLP > RNN , LSTM(Big Brother of RNN)) >> In case of chatgpt we give text data input and the output we get from it is also in text format in its own language >> Language Translation \n",
    "2. Image Data (CNN , ANN) >> AI image ,>> Lenskart (CHoosing Frames option)\n",
    "3. Audio Data (Audio analytics) >> Voice cloning , Audio data of customers can be used by Industry to see if the customer is happy or not while talking to Customer Service.\n",
    "4. Video Analytics >> We know our universe is continuously expanding so to the calculate the distance of the objects captured NASA uses Video analytics to calculate distance between objects >> In terms of crash test for safety ratings previously multiple crash test were done to calculate the safety of the car use by use of video analytics we can reduce the number of crashes and instead study the safety of the car by a single video.\n",
    "* In Video analytics we convert video into image.\n",
    "\n",
    "> CPU (Central Processing Unit)\n",
    "* General purpose processor for a wide range of tasks.\n",
    "* Few powerful cores optimized for sequential processing.\n",
    "* Suited for complex decision making and control flow.\n",
    "\n",
    "> GPU (Graphics Processing Unit)\n",
    "* Originally designed for graphics rendering and parallel processing.\n",
    "* Many small, Specialized cores for parallel tasks.\n",
    "* Suited for parallelizable tasks like graphics , machine learning  and simulations.\n",
    "\n",
    "> Cardinality \n",
    "* If we have categorical data in target column we need to do label encoding.\n",
    "* Label encoding is done when we have order in our Categorical data . In case of label encoding if we have more values than the model wil give higher weightage for maximum values( we have 3 to 4 categorical data)\n",
    "* In one hot encoding we will get more features and there will be curse of Dimensionality which is not Good.\n",
    "* Having many categorical values in our features is called as Cardinality.\n",
    "* In Such Cases we use only one technique by deciding the weight of the each category and the error associated with that category in the total feature , in this way we select only category which has high presence and low error.\n",
    "* Cardinality affects vertically in the dataset ( In terms of rows)\n",
    "\n",
    "> Curse of Dimensionality\n",
    "* Higher number of Independent features causes Curse of Dimensionality\n",
    "* It affects the data Horizontally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Perceptron > Before deep learning we used this ALgorithm.\n",
    "* It is a 2 stage algorithm\n",
    "* It is a part of Machine Learning\n",
    "* Weight,Bias >> External parameters\n",
    "* Suppose we have X1,X2,X3 and X4 as input parameters and we have W1,W2,W3,W4 as weights for each parameter.\n",
    "* And we get Yp as Output Parameter.\n",
    "\n",
    "> Stage 1 (Summation Function) (Z)\n",
    "* As it is a 2 stage algorithm in first stage we will perform Summation (Z)\n",
    "* Z = Summation (Wi * Xi + b) (b = Bias)\n",
    "\n",
    "> Stage 2 (Activation Function) Sigmoid \n",
    "* Sigmoid(Z) = 1 / (1 + e^-Z)\n",
    "* Y predicted will be the output of Sigmoid Function\n",
    "* This whole process is known as perceptron and Perceptron itself act as a Neuron in Neural Network.\n",
    "\n",
    "* Perceptron was used for creating Neural Network and that perceptron is called as Neuron.\n",
    "* Neural Network is made up of n number of different Algorithms.\n",
    "* Hence Neural Network is called as Architecture and not a Algorithm.(ANN , CNN)\n",
    "\n",
    "> What is Sigmoid ?\n",
    "* It is used to add Non Linearity\n",
    "* Sigmoid converts continous values into probablity distribution(Range 0 to 1)\n",
    "* It will always gives probablistic value.\n",
    "* It will give probablity value of any one class.\n",
    "\n",
    "> Structure of Neural Network?\n",
    "* Network >> When there is a connection between Source and link.\n",
    "* When there is a connection between neuron1 and neuron2 then there is neural network.\n",
    "* When Neuron1 and Neuron2 are connected then there is neural network.For connection between the neurons some weight is assigned to this connection.\n",
    "* Bias in this term is different from Machine Learning.\n",
    "* We will apply Bias to the Head of the Neurons.\n",
    "* Input Layer > It holds the input and feed them to hidden layer.\n",
    "* There is only one input layer \n",
    "* Hidden layer > Done all the processing / Learning\n",
    "* Hidden layer can be one or more than one.\n",
    "* If there is only one hidden layer then it is called as Shalow Neural Network.\n",
    "* If there is more than one hidden layer then it is called as Deep Neural Network.\n",
    "* We have our learning only in our Hidden layer.\n",
    "* Output layer > It shows Output\n",
    "* Output layer is always one layer.\n",
    "\n",
    "> How data flow in Neural Network?\n",
    "* Number of Neurons in Input Layer = Numbers of input features\n",
    "* Number of Neurons in Output Layer = Decided by the activation function and number of event.\n",
    "\n",
    "> Case 1 Lets say we are dealing with binary classification and in our output layer we have signoid function as activation function?\n",
    "* How many neurons will be there in the output layer?\n",
    "> 1\n",
    "\n",
    "> Case 2  Lets say we are dealing with Multiclass classification and in out output layer we have softmax function as activation function (Softmax activation is used for Multiclass classification and it is the modified version of Sigmoid activation) and number of events is 5.\n",
    "* How many neurons will be there in the output layer?\n",
    "> 5\n",
    "\n",
    "> Case 3 Lets say we are dealing with regression problems and in our output layer we have relu as a activation function (Relu activation is used for regression)\n",
    "* How many neurons will be there in the output layer?\n",
    "> 1\n",
    "\n",
    "* We have 7 to 8 activation functions \n",
    "* Number of Neurons in the output will depend on the activation function.\n",
    "\n",
    "> Number of Neurons in the Hidden Layer?\n",
    "* Not fixed \n",
    "\n",
    "> General Thumb rule (Manually building ANN)\n",
    "* If we have 15 neurons as input layer and we are getting 3 Neurons in the output layer so naturally the neurons in the hidden layer will be in the range(3 to 15)\n",
    "* If we increase the number of neurons (Neuron itself is a Algorithm) our complexity of the architecture(Neural Network) will increase and our computational cost and time will increase and more resources will be used.\n",
    "\n",
    "> Shape of the Layers \n",
    "* If we have 3 Neurons in 1 Container as our input layer then we say that the shape of the input layer is (1,3).\n",
    "* Likewise we have shape of the hidden layer 1 as (1,4) and shape of the hidden layer 2 as (1,2) and shape of the output layer is (1,1).\n",
    "\n",
    "> How to control shape of the layers is Neural Network?\n",
    "* Lets Consider W1 (Weight matrix) and we start from 3 neurons and we end with 4 neurons.\n",
    "* We will get 12 connections and we will get weight for each connection that is we will get 12 weights.\n",
    "* So the shape of W1 will be (4,3)\n",
    "* Z = Summation (Wi * Xi + b)\n",
    "* Z = Summation (Wi^T * Xi + b) >> T = Transpose\n",
    "* Weight decide the shape of the Layers \n",
    "\n",
    "> Importance of BIAS ?\n",
    "* Bias is a 1 Dimensional array that consists value of Bias.\n",
    "> Z = Summation (Wi * Xi + b)\n",
    "* Even if we have 0 as the value of Independent variable while calculating Z we should not get the ouput of that variable as Zero we add Bias . Or we can also say that to add importance to that feature we add Bias.\n",
    "\n",
    "> How Neural Network Learns?\n",
    "* We folow a chain rule for selecting optimal weight and bias which are external parameters.\n",
    "* Same steps we followed in Gradient Descent in Linear regression for finding optimal m and c values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Perceptron > before deep learning we used this algorithm.\n",
    "* It is a 2 stage algorithm\n",
    "* It is a part of Machine Learning.\n",
    "* Weight,bias >> External parameters\n",
    "* Suppose we have X1,X2,X3,X4 as input parameters and we have W1,W2,W3,W4 as weights for each parameters.\n",
    "* And we get Yp as Output Parameter.\n",
    "\n",
    "> Stage 1 (Summation Fucntion) Z\n",
    "* As it is a 2 stage algorithm in first stage we will perform summation (Z)\n",
    "* Z = Summation(Wi * Xi + b)  (b = bias)\n",
    "\n",
    "> Stage 2 (Activation Fucntion) Sigmoid\n",
    "* Z = 1 / (1 + e^-Z)\n",
    "* Y predicted will be the output of the Sigmoid function.\n",
    "* This whole process is known as Perceptron and Perceptron itself acts as Neuron in Neural Network.\n",
    "\n",
    "* Perceptron was used for creating Neural Network and that perceptron is called as Neuron.\n",
    "* Neural Network is made up of n numbers of different Algorithms.\n",
    "* Hence Neural Network is called as an Architecture and not a Algorithm.\n",
    "\n",
    "> What is Sigmoid?\n",
    "* It is used to add Non linearity.\n",
    "* Sigmoid converts continous values into probablity distribution. (Range 0 to 1)\n",
    "* It always gives probablistic values.\n",
    "* It always gives probablity value of any one class.\n",
    "\n",
    "> Structure of Neural Network\n",
    "* Network >> When there is connection between Source and link.\n",
    "* When there is a connection between Neuron1 and Neuron2 then there is Neural Network.\n",
    "* When Neuron1 and Neuron2 are connected then there is Neural Network.For connection between the Neurons some weight is assigned to this connection.\n",
    "* Bias in this term is different from Machine Learning.\n",
    "* We will apply Bias to the Head of Neurons.\n",
    "* Input Layer > It hold the input and feed them to hidden layer.\n",
    "* There is only one input layer.\n",
    "* Hidden layer >> Done all the processing / Learning\n",
    "* Hidden layer can be more than one.\n",
    "* If there is only one hidden layer then it is called as Shalow Neural Network.\n",
    "* If there is more than one hidden layer then it is called as Deep Neural Network.\n",
    "* We have our Learning only in our hidden layer.\n",
    "* Output layer >> It shows Output\n",
    "* Output layer is always one layer.\n",
    "\n",
    "> How data flow in Neural Networks?\n",
    "* Number of neuron in Input Layer = Number of input features\n",
    "* Number of neurons in Output Layer = Decided by the activation function and number of event.\n",
    "\n",
    "> Case 1 Lets say we are dealing with binary classification and in our output layer we have Sigmoid activation function.\n",
    "* How many neurons will be there in the output layer?\n",
    "> 1\n",
    "\n",
    "> Case 2 Lets say we are dealing with Multiclass classification and in our output layer we have softmax activation function (SoftMax activation is used for Multiclass classification and is the modified version of Sigmoid activation) and number of event is 5\n",
    "* How many neurons will be there in the output layer?\n",
    "> 5\n",
    "\n",
    "> Case 3 Lets say we that we are dealing with regression problems and in our output layer we have Relu as a activation function (Relu activation is used for regression)\n",
    "* How many neurons will be there in the output layer?\n",
    "> 1 (Continous Values)\n",
    "\n",
    "* We have 7 to 8 activation functions.\n",
    "* Number of neurons in the output layer will depend on the activation function.\n",
    "\n",
    "> Number of Neurons in the hidden layer?\n",
    "* Not Fixed\n",
    "\n",
    "> General Thumb Rule (Manually building ANN)\n",
    "* If we have 15 neurons as input layer and we are getting 3 neurons in the output layer so naturally the neurons in the hidden layer will be in the range(3 to 15)\n",
    "* If we increase the number of neurons (Neuron is itself a Algorithm) our complexity of the architecture (Neural Network) will increase and our Computation cost and time will increase and more resources will be used.\n",
    "\n",
    "> Shape of the Layers \n",
    "* If we have 3 Neurons in 1 Container as our input layer then we say the shape of the Input Layer is = (1,3).\n",
    "* Likewise we have shape of the hidden layer 1 as (1,4) and shape of the Hidden Layer 2 as (1,2) and shape of the output layer is (1,1).\n",
    "\n",
    "> How to control shape of the Layers in Neural Network?\n",
    "* Lets consider W1 (weight Matrix) and we start from 3 Neurons and we end with 4 Neurons.\n",
    "* We will get 12 connections and we will get weight for each connection that is we will get 12 weights.\n",
    "* So the shape of W1 will be (4,3)\n",
    "* Z = Summation (Wi * Xi + b)\n",
    "* Z = Summation (Wi^T * Xi + b) >> T = Transpose\n",
    "* weight decide the shape of the layers.\n",
    "\n",
    "> Importance of Bias \n",
    "* Bias is a 1 dimensional array that consists values of Bias.\n",
    "> Z = Summation(Wi * Xi + b) \n",
    "* Even if we have 0 as the value of Independent variable while calculating Z we should not get the output of that variable as zero we add Bias.Or we can also say that to add importance to that feature we add Bias.\n",
    "\n",
    "> How Neural Network learns?\n",
    "* We follow a chain rule for selecting optimal weight and Bias which are external parameters.\n",
    "* Same steps we follow in Gradient Descent in Linear regression for finding optimal m and c values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
