{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "* It is a predictive model used to find linear relationships between independent variables and dependent variable.\n",
    "* Which means that linear regression is used to find how dependent variable changes with a change in independent variables.\n",
    "* It is a parametric algorithm >> assumptions on distribition of data\n",
    "* our main aim of linear regression is to find out the linear relationship between independent variables and dependent variable.\n",
    "* The Goal of the linear regression is to find the best fit line that can accurately predict the output fot the continous dependent variable.\n",
    "\n",
    "> Types of Linear Regression\n",
    "1. Simple Linear Regression\n",
    "* If a single independent variable is used to predict the the value of numerical independent variable then such a linear regression algorithm is called Simple Linear Regression.\n",
    "* Only one independent variables.\n",
    "* Y = mX + C\n",
    "* m >> Slope >> Linear Regression coefficient \n",
    "* C >> Intercept of the line \n",
    "* X >> Independent variable\n",
    "* Y >> Dependent variable\n",
    "\n",
    "2. Multiple Linear Regression\n",
    "* If more than one independent variable is used to predict the value of numerical dependent variable then such a linear regression is called as Multiple linear regression.\n",
    "* Two or more independent variables\n",
    "> Y = m1X1 + m2X2 + m3X3 + C\n",
    "* m1,m2,m3 are the slopes of independent variable \n",
    "* X1,X2,X3 are the independent variable\n",
    "* Y >> Dependent varaiable \n",
    "* Slope >> m = (Y2 - Y1) / (X2 - X1)\n",
    "\n",
    "> Residuals or errors or coefficient of regression (e)\n",
    "* The distance between the actual and predicted values is called as residuals.\n",
    "* If the observed points are far away from the regression line then the residual will be high and so cost function will be also high.\n",
    "* If the observed points are near the regression line then the residual will be low and so cost function will be also low.\n",
    "> e = Yactual - Ypredicted\n",
    "* Yactual >> actual value of Y >> original value  >> data point\n",
    "* Ypredicted >> predicted value of Y >> value according to the regression line \n",
    "\n",
    "> Linear regression line \n",
    "* A linear line showing the relationship between the independent variables and dependent variable is called a linear regression line. A linear regression line can show 2 types of regression line.\n",
    "1. Positive linear relationship >> R = 1 \n",
    "* If the dependent variable increases by increasing the values independent variable then such a relationship is called as a positive linear relationship.\n",
    "2. Negative linear relationship >> R = -1\n",
    "* If the dependent variable decreases by decreasing the values independent variable then such a relationship is called as a negative linear relationship.\n",
    "\n",
    "> Advantages of Linear regression \n",
    "1. Simple to implement and easier to interpret the output coefficients\n",
    "2. When you know there is a linear relationship between independent variables and dependent variables then this is the best algorithm is best to use as compares to other complex algorithm\n",
    "3. Linear regression is prone to overfitting to avoid these problem we use dimensionality reduction technique , regularization(L1 and L2),cross validation \n",
    "\n",
    "> Disadvantages of linear regression \n",
    "1. If the independent features are corelated to each other then it may affect the performance of the model.\n",
    "2. It is only efficient if there is a linear relationsio between the independent variable and dependent variable .\n",
    "3. Sometimes a lot of feature engineering is required.\n",
    "4. Scaling is required \n",
    "5. It is often prone to noise and overfitting\n",
    "6. It is sensitive to missing values \n",
    "7. It is sensitive to outliers\n",
    "\n",
    "> Applications of linear regression\n",
    "1. Forecasting the data\n",
    "2. Analyzing the time series\n",
    "3. Price prediction\n",
    "4. Salary prediction\n",
    "\n",
    "> Assumptions of linear regression\n",
    "1. Linearity >> Linear relationship between the independent variable and dependent varaiable \n",
    "2. No multicolinearity >> All the independent variable should be independent to each other.\n",
    "3. Normality of residual \n",
    "4. Homoscedasticity >> Variance of residual is same or constant at every level of X\n",
    "\n",
    "\n",
    "> Linearity \n",
    "* There should be linear relationship between the independent variable and dependent variable.\n",
    "* A linear relationship between independent variable and dependent varaible says that a unit change in Independent variable there is a unit change in dependent varaiable \n",
    "* In linear regression a straight line will be passed through maximum data points.\n",
    "* So due to that Coefficient of reression is minimum.\n",
    "* It shows strong linear relationship between the independent varaiable and dependent variable\n",
    "\n",
    "> How to check Linearity ?\n",
    "1. Coefficient of corelation \n",
    "2. Scatterplot\n",
    "3. Corelation matrix\n",
    "\n",
    "> How to handle linearity if violated ?\n",
    "* Apply a non linear transformation to the independent and dependent variables.\n",
    "1. Log transformation\n",
    "2. Square root transformation\n",
    "3. Reciprocal transformation\n",
    "\n",
    "> What if these linearity get violated?\n",
    "* If our linearity gets violated then it says that our best fit line doenot pass through the maximum data points which says that there in no linear relationship between the independent and dependent variables and due to which our coeffiient of regression is maximum . It Shows non linear relationship between the independent and dependent variables resulting in inefficent model this will result in wrong predictions of output.\n",
    "\n",
    "> No Multcolinearity \n",
    "* All the independent variables should be independent to each other is called NoMultcolinearity \n",
    "* There should be no linear relationship between two independent variables.\n",
    "* Multicolinearity >> It occurs when independent variables are corelated to each other.\n",
    "* If there is Multicolinearity that means that an independent variable can be predicted from another independent variable.\n",
    "* Multicolinearity can be a problem in a regression model because we would not be able to distinguish the effects of the independent variable on dependent variables.\n",
    "* Y = m1X1 + m2X2 + m3X3 + C\n",
    "* Coefficient m1 is the increase in Y for a unit increase in X1 while keeping X2 constant \n",
    "* But since X1 and X2 are highly corelated to each other changes in X1 would also cause changes in X2 and we would not be able to see their individual effects on Y.\n",
    "* Multicolinearity may not affect the accuracy of the model as much .But we might lose reliability in detrmining the effects of individual features in your model and that can be a problem when it comes to interpretability .\n",
    "* Multicolinearity means high corelation between two or more independent variables.\n",
    "* Due to multcolinearity it may be difficult to find the true realtionship between the independent variables and the dependent variable.\n",
    "* So the model assumes either little or no multicolinearity between the independent variables.\n",
    "* Regression equation >> \n",
    "> Y = m1X1 + m2X2 + m3X3 + C\n",
    "* If 2 independent variables are independent on each other then changes in X1 will be affected on X2 and , as m1 is the coefficent where m1 is the increase in Y for a unit increase in X1 while keeping X2 constant ,above condition will be false as changes in X1 are affected on X2 so model will face problems for calculating m1 and m2 values .\n",
    "* It is difficult to determine which independent variable is affecting the dependent variable and which is not .\n",
    "* So it is important of no multicloinearity in our module .\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
