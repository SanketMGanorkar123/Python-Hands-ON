{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What made you switch your career to DataScience?\n",
    "# 2. Why you want to resign from current job?\n",
    "# 3. What Package you are expecting (In HR round)?\n",
    "> Whichever comapny has called for interview search about its history whther it is Product based or Service based Industry.\n",
    "# Why projects actually exists(Service based)?\n",
    "1. Time Management\n",
    "2. Automation \n",
    "3. Process Management \n",
    "4. Revenue Generation >> Maximization\n",
    "5. Revenue loss >> Optimization \n",
    "> Proof of Concept > POC > Paid or Unpaid \n",
    "> Duration of POC > 2-3 months , 6 months , 1 year \n",
    "* \n",
    "> In POC we get Problem statement / Business problems / Business requirements / What was the Business scenario\n",
    "* Approach towards project > Python \n",
    "                           > MAchine learning\n",
    "                           > NLP\n",
    "                           > Deep Learning\n",
    "                           > Time Series Analysis \n",
    "> Product based Industry have their own database and we can retrieve data from database.\n",
    "> Who are the people involved in the project?\n",
    "1. Project Manager  - 01 \n",
    "2. Team Leader      - 01 \n",
    "3. Business Analyst - 01\n",
    "4. Data Engineer    - 01 or 02 >>  Data Engineer fetches data from database\n",
    "5. Data Scientist   - 01\n",
    "6. ML Engineer      - 01 \n",
    "7. Python Developer - 01  >> For Web Framework(Flask , Django , FastAPI , gRPC)\n",
    "8. Power Bi Engineer- 01  >> For Data Visualization\n",
    "9. DevOps Engineer  - 01 or 02 >> For Project deployment (Cloud platform : AWS , Azure(Azure ML) , GCP)\n",
    "10. Front end developer : UX Designer >> Create Design \n",
    "                        : UI Developer >> Integrate API \n",
    "> Project Planning \n",
    "* Project planning Tools \n",
    "1. JIRA \n",
    "2. Zoho \n",
    "3. Trello \n",
    "4. Asana \n",
    "> Pipeline : In Industry we are getting data seperate for training and seperate for testing . we will write single functions in which we carry out necessary steps (EDA , Feature Engineering , Feature selection) and then we will call the same function for testing data. So in this way we are creating a pipleine (flow) for all steps.\n",
    "> Docker : It is used for creating pipeline(Flow / Connection) .It works as a Ship carrying different containers.\n",
    "* Generally when we create a model and depoly it , we will do some observations . In Observation we will see how our model is performing on new data and we will monitor this process. This process is called as CICD pipeline (Continous integration and Continous Developement). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* During call with HR ask him about JD(Job Description).\n",
    "* 1st round is generalized round (Introduction , end of the introduction will decide the further interview)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Project \n",
    "* First step is project planning and timeline.So for this purpose we use project planning tools (JIRA)\n",
    "* In big Industries we will use JIRA and in small scale companies we will use Excel file for project planning.\n",
    "> Kickoff Meeting : The first meeting when the project is asiggned we will discuss project agenda , project team , introduction.\n",
    "> Onboarding of project / Project kickoff : \n",
    "* Client meet \n",
    "* Project problem discussion\n",
    "* PPT / Deck\n",
    "* Main work \n",
    "* Project Management : JIRA , ZOHO , Trello , Asana \n",
    "> Project Duration / Project timeline >> It will be decided by Higher Authorities(Project Manager , Team Lead , Technical lead)\n",
    "* \n",
    "> VDE (Virtual desktop Environment) : \n",
    "1. Local System(Laptop/Computer) : System available with you physically and you are working on it.\n",
    "2. Virtual system(vmware) : System where you can login online and it has interface as local system.\n",
    "> While scheduling the interview with Hr tell him let me check my calendar wall and then we will schedule the interview.\n",
    "> ScrumMaster(Big Companies) : Person who handles the JIRA software and gives updates.In small company Team Lead will be the scrum master.\n",
    "* \n",
    "> Epic(JIRA) >> Project plan >> suppose 5months \n",
    "* Data Gathering \n",
    "* EDA \n",
    "* Feature Engineering\n",
    "* Feature Selection\n",
    "* Model Building \n",
    "> Subpart of Epic >> Sprint (1 Week or 2 Week) :\n",
    "* Within Sprint we will have subparts as story1 and story2 . Suppose we have story1 as Data Gathering and story2 as EDA.\n",
    "* We can have multiple Sprints.And in that Sprint we can have multiple stories.\n",
    "> Issues : Problems faced \n",
    "* \n",
    "> From where do we get the data?\n",
    "* We will get data from different Databases(MySQL , PostgreSQL , MongoDB(NoSQL) ,Company DataBase(Product Based), client DataBase,Cloud S3 Bucket (Sagemaker) , Data Engineer) in the form of CSV , Excel , JSON , Text.\n",
    "* Data Engineer fetches data from Databases and will send it to us by mail on CLient mailid.\n",
    "> Web Scrapping (Sentiment Analysis , NLP ,Movie reviews) for data.\n",
    "* Sometimes the client can only provide the feature names.For Data we can use Kaggle or other resources.\n",
    "> Synthetic Data Generation : Hugging Face \n",
    "* \n",
    "> DataBase access : Read and write access \n",
    "* \n",
    "> Evironment access(Done after project completion)   \n",
    "1. Production Environment\n",
    "2. Testing Environment(SandBox)\n",
    "* First we will deploy our model on Testing Environment and after it is performing good we will go for Production Environment.\n",
    "* \n",
    "> What was your data size?\n",
    "* 0.5 Million to 2 million >> Rows \n",
    "* 10 to 40 >> Features \n",
    "> Features \n",
    "1. Original features\n",
    "2. Derived features >> New features that we can introduce \n",
    "* Suppose we have house price prediction and we want to derive new features.\n",
    "> Celonis : Process mining tool , it uses a vertica sequel same as sql \n",
    "> How frequently your data was updating?\n",
    "* Suppose we have 100000 rows and 25 features and the data was updating to 200000 rows and 30 features.\n",
    "> How frequently was your meeting with clients?\n",
    "* Weekly , 15 days ,Biweekly ,alternate days \n",
    "> What was your role in CLient Meeting?\n",
    "* As a Data Scientist i would discuss technical problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After creating resume when we upload resume on Naukri \n",
    "1. Hr Dynamic >> Resume >> Naukri >> Call(Hr) >> Discussion >> Interview schedule \n",
    "2. In Company > \n",
    "* After joining >> They will use you as shadow resource \n",
    "> Shadow Resource : Some part of existing work will be allocated to you.\n",
    "> Probation period : Starting period >> 3 to 6 months > Temporary >> After 3 to 6 months we will taken On Role in Industry.\n",
    "* New project >> Team Finalize \n",
    "              >> Internal meeting : Introduction to team members \n",
    "              >> Project Kickoff : With Client \n",
    "              >> OnBoarding >> VM Credentials >> Userid , Password , token generation \n",
    "              >> Project Management : Tools >> (JIRA) \n",
    "              >> NDA >> Non Disclosure Agreement\n",
    "* List >> Required features from the client.\n",
    "* Then the client will add the required features in Database.\n",
    "* We will get the required features from different tables and after joining these all tables we will get a MasterTable or Masterdata.\n",
    "* MasterTable will be given to Data Scientist.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "> Note : EDA and Feature Engineering will be different for different Algorithms.\n",
    "> Basic EDA \n",
    "1. Data obsevations \n",
    "* Independence \n",
    "* Balancing \n",
    "* Anomaly Detection (disturbance in the data >> duplicate rows(df.drop_duplicates))\n",
    "* distribution of the data\n",
    "* data sanity >> Coefficient of Corelation , VIF\n",
    "\n",
    "* EDA has 2 types \n",
    "> Univariate and Multivariate analysis\n",
    "* Univariate analysis is where only one feature is used and in Multivariate analysis we use more that one feature.\n",
    "* Handling Missing values \n",
    "* Delete the Observations \n",
    "* Imputation  >> Continous data >> Mean , median ,KNN imputer (Nan Euclidean distance) , MICE\n",
    "               >> Categorical Data >> mode , KNN imputer(k=1) \n",
    "> What is difference between normal distribution and binomial distribution?\n",
    "1. Normal Distribution \n",
    "* Used in situations where the data follows a continous , symmetric distribution.\n",
    "* Commonly used in statistical interference and hypothesis testing.\n",
    "2. Binomail Distribution \n",
    "* Used when dealing with discrete set of trials with two possible outcomes.\n",
    "* Commonly used in scenarios involving binary events(Success / Failure) , such as coin flips or pass/fail situations.\n",
    "> Normal Distribution is more appropriate for continous variables , while binomial distribution is more appropriate for dicrete variables with a fixed number of trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
