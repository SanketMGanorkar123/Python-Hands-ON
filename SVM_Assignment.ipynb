{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "* Before the sudden rise of neural networks ,SVM was considered the most powerful machine learning algorithm.Still it is more comutationally friendly as compared to Neural networks and used extensively in Industries. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What are Support Vector Machines (SVMs)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SVM is a supervised machine learning algorithm that works on both classification and regression problems.\n",
    "* For a classification problem it tries to differentiate data points of different classes by finding a hyperplane that maximizes the margin between the classes in the training data.\n",
    "* In simple words SVM tries to choose the hyperplane which seperates the data points as widely as possible since this margin maximization improves the models accuracy on the test or the unseen data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.What are support vectors in SVMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Support vector are those instances that are located on the margin itself.For SVMs the decision boundary is entirely determined by using only the support vectors.\n",
    "* ANy Instance that is not a support vector (Not on the margin boundaries) has no influence whatsoever you colud remove them or add more instances or move them around and as they stay off the margin they wont affect the decision boundary.\n",
    "* For computing the prediction only the support vector are involved not the whole training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. What is the basic principle of a support vector machine?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Its aimed at finding an optimal hyperplane that is linealry seperable and for the dataset which is not directly lienarly seperable, it extends its formulation by transforming the original data to map into a new space which is also called Kernel Trick.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. What are Hard Margins and Soft Margins in SVMs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hard margin SVMs work only if the data is linearly seperable and these types of SVMs are quite sensitive to the outliers. But our main objective is to find a good balance between keeping the margins as large as possible and limiting the margin violation. I.e instaces that end up in the middle of margin or even on the wrong side and this method is called as Soft Margin SVM ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. What do you mean by Hinge Loss ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The functions defined by max(0,1-t) is called as Hinge loss function.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
